{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 615299 bounding boxes across 544546 images.\n",
      "Determining list of input files and labels from ../../data/imagenet/data/validation/.\n",
      "Finished finding files in 100 of 1000 classes.\n",
      "Finished finding files in 200 of 1000 classes.\n",
      "Finished finding files in 300 of 1000 classes.\n",
      "Finished finding files in 400 of 1000 classes.\n",
      "Finished finding files in 500 of 1000 classes.\n",
      "Finished finding files in 600 of 1000 classes.\n",
      "Finished finding files in 700 of 1000 classes.\n",
      "Finished finding files in 800 of 1000 classes.\n",
      "Finished finding files in 900 of 1000 classes.\n",
      "Finished finding files in 1000 of 1000 classes.\n",
      "Found 50000 JPEG files across 1000 labels inside ../../data/imagenet/data/validation/.\n",
      "Determining list of input files and labels from ../../data/imagenet/data/train/.\n",
      "Finished finding files in 100 of 1000 classes.\n",
      "Finished finding files in 200 of 1000 classes.\n",
      "Finished finding files in 300 of 1000 classes.\n",
      "Finished finding files in 400 of 1000 classes.\n",
      "Finished finding files in 500 of 1000 classes.\n",
      "Finished finding files in 600 of 1000 classes.\n",
      "Finished finding files in 700 of 1000 classes.\n",
      "Finished finding files in 800 of 1000 classes.\n",
      "Finished finding files in 900 of 1000 classes.\n",
      "Finished finding files in 1000 of 1000 classes.\n",
      "Found 530070 JPEG files across 1000 labels inside ../../data/imagenet/data/train/.\n",
      "Loading imagenet data\n",
      "Train directory seems to exist\n",
      "Validation directory seems to exist\n",
      "WARNING:tensorflow:From /project/notebooks/deep-compression/imagenet.py:353: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:751: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:751: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /project/notebooks/deep-compression/imagenet.py:376: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    from imagenet import imagenet_data\n",
    "    d = imagenet_data(batch_size=64, sess=sess)\n",
    "    X_train, y_train = d.build_train_data_tensor()\n",
    "    X_test, y_test = d.build_test_data_tensor(shuffle=True, augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  0\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  1\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  2\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  3\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  4\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  5\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  6\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  7\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  8\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "batch  9\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "(64, 299, 299, 3) (64, 1000)\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"batch \", i)\n",
    "    train_batch, train_labels, test_batch, test_labels  = sess.run([X_train, y_train, X_test, y_test])\n",
    "    print(train_batch.shape, train_labels.shape)\n",
    "    print(test_batch.shape, test_labels.shape)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Well, almost. Closing the queue and the session. This will lead to the following warning/error ...\")\n",
    "d.close()\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
